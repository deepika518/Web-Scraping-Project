{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f6d0c50",
   "metadata": {},
   "source": [
    "# Scraping Top Repositories for Topics on GitHub\n",
    "\n",
    "Tools used: Python, requests, BeautifulSoup, Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf0bfc5",
   "metadata": {},
   "source": [
    "### Project Outline\n",
    "\n",
    "- Scrape the 'topics' page of GitHub https://github.com/topics\n",
    "- Get list of all the topics and for each topic, get the topic title, topic description and topic URL\n",
    "- For each topic, get the top  n repositories\n",
    "- For each repository, get the repo name, username, stars and repo URL\n",
    "- For each topic, create a CSV file in the following format-\n",
    "'''\n",
    "Repo Name, Username, Stars, URL\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213d6a39",
   "metadata": {},
   "source": [
    "## Scrape the list of topics from GitHub\n",
    "\n",
    "- Using requests library to download the page\n",
    "- Using bs4 to parse and extract information\n",
    "- Convert that into a pandas dataframe\n",
    "\n",
    "For that, writing the function to download the page-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "921ef709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_topics_page():\n",
    "    # returns a Beautiful Soup Document containing a parsed web page containing list of topics\n",
    "    topics_url = 'https://github.com/topics'\n",
    "    # Download the page\n",
    "    response = requests.get(topics_url)\n",
    "    # Check successful response \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f'failed to load page {topics_url}')\n",
    "    # Parse the page using Beautiful Soup\n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf19cf3",
   "metadata": {},
   "source": [
    "Adding some explanation of this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce090dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = get_topics_page()\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c1d28b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"px-2 py-4 color-bg-accent-emphasis color-fg-on-emphasis show-on-focus js-skip-to-content\" href=\"#start-of-content\">Skip to content</a>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.find('a')      #parses the first 'a' tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a252486",
   "metadata": {},
   "source": [
    "Functions to parse information of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63bb68c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the list of topics titles\n",
    "def get_topic_titles(doc):\n",
    "    # Getting the list of all the tags containing title text by inspecting the browser\n",
    "    topic_title_tags = doc.find_all('p', class_ = 'f3 lh-condensed mb-0 mt-1 Link--primary')\n",
    "    #List to store titles extracted from tags\n",
    "    topic_titles=[]\n",
    "    #Iterating through the list of tags to get the text and storing it in the list\n",
    "    for tag in topic_title_tags:\n",
    "        topic_titles.append(tag.text) \n",
    "    return topic_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8827cb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3D', 'Ajax', 'Algorithm', 'Amp', 'Android']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_topic_titles(doc)[:5]   # 'doc' is the returned document from get_topic_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "178f48c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the list of topics descriptions\n",
    "def get_topic_descs(doc):\n",
    "    # Getting the list of all the tags containing description text by inspecting the browser\n",
    "    topic_desc_tags = doc.find_all('p', class_ = 'f5 color-fg-muted mb-0 mt-1')\n",
    "    #List to store descriptions extracted from tags\n",
    "    topic_descs=[]\n",
    "    #Iterating through the list of tags to get the text and storing it in the list\n",
    "    for tag in topic_desc_tags:\n",
    "        topic_descs.append(tag.text.strip())\n",
    "    return topic_descs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2ac5e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3D modeling is the process of virtually developing the surface and structure of a 3D object.',\n",
       " 'Ajax is a technique for creating interactive web applications.',\n",
       " 'Algorithms are self-contained sequences that carry out a variety of tasks.',\n",
       " 'Amp is a non-blocking concurrency library for PHP.',\n",
       " 'Android is an operating system built by Google designed for mobile devices.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_topic_descs(doc)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b37bfb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the list of topics URLs\n",
    "def get_topic_urls(doc):\n",
    "    # Getting the list of all the tags containing url by inspecting the browser\n",
    "    topic_url_tags = doc.find_all('a', class_ = 'no-underline flex-1 d-flex flex-column')\n",
    "    #List to store urls extracted from tags\n",
    "    topic_urls=[]\n",
    "    #Iterating through the list of tags to get the url and storing it in the list\n",
    "    for tag in topic_url_tags:\n",
    "        topic_urls.append('https://github.com'+ tag['href'])\n",
    "    return topic_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e1477bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/topics/3d',\n",
       " 'https://github.com/topics/ajax',\n",
       " 'https://github.com/topics/algorithm',\n",
       " 'https://github.com/topics/amphp',\n",
       " 'https://github.com/topics/android']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_topic_urls(doc)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a57bcb7",
   "metadata": {},
   "source": [
    "Putting all the above functions in a single function returning dataframe of all topics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf845a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it returns the dataframe of information(title, description and url) of GitHub topics\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_topics():\n",
    "    #Getting the page for parsing\n",
    "    doc = get_topics_page()\n",
    "    # Dictionary to store all the lists of respective information\n",
    "    topics_dict={\n",
    "        'title': get_topic_titles(doc),      #Getting list of titles\n",
    "        'description': get_topic_descs(doc), #Gettting list of dscription\n",
    "        'url': get_topic_urls(doc)           #Getting list of urls\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(topics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af1340f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D</td>\n",
       "      <td>3D modeling is the process of virtually develo...</td>\n",
       "      <td>https://github.com/topics/3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ajax</td>\n",
       "      <td>Ajax is a technique for creating interactive w...</td>\n",
       "      <td>https://github.com/topics/ajax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algorithm</td>\n",
       "      <td>Algorithms are self-contained sequences that c...</td>\n",
       "      <td>https://github.com/topics/algorithm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amp</td>\n",
       "      <td>Amp is a non-blocking concurrency library for ...</td>\n",
       "      <td>https://github.com/topics/amphp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Android</td>\n",
       "      <td>Android is an operating system built by Google...</td>\n",
       "      <td>https://github.com/topics/android</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title                                        description  \\\n",
       "0         3D  3D modeling is the process of virtually develo...   \n",
       "1       Ajax  Ajax is a technique for creating interactive w...   \n",
       "2  Algorithm  Algorithms are self-contained sequences that c...   \n",
       "3        Amp  Amp is a non-blocking concurrency library for ...   \n",
       "4    Android  Android is an operating system built by Google...   \n",
       "\n",
       "                                   url  \n",
       "0         https://github.com/topics/3d  \n",
       "1       https://github.com/topics/ajax  \n",
       "2  https://github.com/topics/algorithm  \n",
       "3      https://github.com/topics/amphp  \n",
       "4    https://github.com/topics/android  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_topics().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c06de9",
   "metadata": {},
   "source": [
    "## Get the top repositories from a topic page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2975a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it takes the url of a topic page and returns its parsed page\n",
    "def get_topic_page(topic_url):\n",
    "    # Download the page\n",
    "    response = requests.get(topic_url)\n",
    "    # Check successful response \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f'failed to load page {topic_url}')\n",
    "    # Parse the page using Beautiful Soup\n",
    "    topic_doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return topic_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db5d854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_doc = get_topic_page('https://github.com/topics/3d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab733af5",
   "metadata": {},
   "source": [
    "- To get the top repos of a topic, the 'username', 'repo name', 'repo url' and 'stars' need to be extracted.\n",
    "\n",
    "- For that, while inspecting the page, the username, repo name and repo url were found in two children ('a') tags of a parent ('h3') tag.\n",
    "- So, first the 'h3' tags are extracted to reach its childern, 'a' tags.\n",
    "- Stars were found in separate 'span' tags.\n",
    "\n",
    "- So, to get the info of the topic, the 'h' tags (for username, repo name and repo url) and the coresponding star tags are passed in the following function and it returns the list of username, repo name, repo url and stars of the topic.\n",
    "- To get stars in integer format, a separate function is built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aabb5a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes the star string and returns the whole number of stars\n",
    "def parse_star_tags(star_str):\n",
    "    star_str=star_str.strip()\n",
    "    if star_str[-1]=='k':\n",
    "        return int(float(star_str[:-1])*1000)\n",
    "    return int(star_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a29bbb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_info(h_tag, star_tag):\n",
    "    # returns all information required about a repository\n",
    "    \n",
    "    # Gettting childern tags from the parent tag\n",
    "    a_tags = h_tag.find_all('a')\n",
    "    # Getting username from first child tag\n",
    "    username = a_tags[0].text.strip()\n",
    "    # Getting repo name from second child tag\n",
    "    repo_name = a_tags[1].text.strip()\n",
    "    # Getting repo url from 2nd child tag and concatenating it with base url to get complete url\n",
    "    repo_url = 'https://github.com' + a_tags[1]['href']\n",
    "    # Getting stars in in interger format\n",
    "    stars = parse_star_tags(star_tag.text.strip())\n",
    "    return username, repo_name, repo_url, stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e08f0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mrdoob', 'three.js', 'https://github.com/mrdoob/three.js', 84100)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting information of first repository of '3d' topic\n",
    "\n",
    "h_tag = topic_doc.find('h3', class_ = 'f3 color-fg-muted text-normal lh-condensed')\n",
    "star_tag = topic_doc.find('span', {'class' : 'Counter js-social-count'})\n",
    "get_repo_info(h_tag, star_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12b1eae",
   "metadata": {},
   "source": [
    "Now the following function takes the parsed page of topic and returns all the repositories in pandas dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4353b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_repos(topic_doc):\n",
    "   \n",
    "    # Get the list of repo tags which contains username, repo name and repo url\n",
    "    repo_tags = topic_doc.find_all('h3', class_ = 'f3 color-fg-muted text-normal lh-condensed')\n",
    "    # Get the list of star tags\n",
    "    star_tags = topic_doc.find_all('span', {'class' : 'Counter js-social-count'})\n",
    "    # Creating a dictionary to store repo info\n",
    "    topic_repos_dict={\n",
    "    'username':[],\n",
    "    'repo name':[],\n",
    "    'repo url': [],\n",
    "    'stars': []\n",
    "    }\n",
    "    # Getting repos\n",
    "    for i in range(len(repo_tags)):\n",
    "        repo_info = get_repo_info(repo_tags[i], star_tags[i])\n",
    "        topic_repos_dict['username'].append(repo_info[0])\n",
    "        topic_repos_dict['repo name'].append(repo_info[1])\n",
    "        topic_repos_dict['repo url'].append(repo_info[2])\n",
    "        topic_repos_dict['stars'].append(repo_info[3])\n",
    "    # Returning a dataframe of repositories made from dictionary\n",
    "    return pd.DataFrame(topic_repos_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f3dabf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>repo name</th>\n",
       "      <th>repo url</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mrdoob</td>\n",
       "      <td>three.js</td>\n",
       "      <td>https://github.com/mrdoob/three.js</td>\n",
       "      <td>84100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>libgdx</td>\n",
       "      <td>libgdx</td>\n",
       "      <td>https://github.com/libgdx/libgdx</td>\n",
       "      <td>20300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pmndrs</td>\n",
       "      <td>react-three-fiber</td>\n",
       "      <td>https://github.com/pmndrs/react-three-fiber</td>\n",
       "      <td>19000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BabylonJS</td>\n",
       "      <td>Babylon.js</td>\n",
       "      <td>https://github.com/BabylonJS/Babylon.js</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aframevr</td>\n",
       "      <td>aframe</td>\n",
       "      <td>https://github.com/aframevr/aframe</td>\n",
       "      <td>14400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    username          repo name                                     repo url  \\\n",
       "0     mrdoob           three.js           https://github.com/mrdoob/three.js   \n",
       "1     libgdx             libgdx             https://github.com/libgdx/libgdx   \n",
       "2     pmndrs  react-three-fiber  https://github.com/pmndrs/react-three-fiber   \n",
       "3  BabylonJS         Babylon.js      https://github.com/BabylonJS/Babylon.js   \n",
       "4   aframevr             aframe           https://github.com/aframevr/aframe   \n",
       "\n",
       "   stars  \n",
       "0  84100  \n",
       "1  20300  \n",
       "2  19000  \n",
       "3  18000  \n",
       "4  14400  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First getting the parsed page of 3D topic\n",
    "topic_doc = get_topic_page('https://github.com/topics/3d')\n",
    "# Then passing it in below function to get dataframe of top repos\n",
    "get_topic_repos(topic_doc).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9b4834",
   "metadata": {},
   "source": [
    "Now the following function exports the dataframe of the top repos of a topic into CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3978c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# it takes the topic url and path of the folder\n",
    "def scrape_topic(topic_url, path):\n",
    "    # Checking if the file already exists in the folder\n",
    "    if os.path.exists(path):\n",
    "        print('The file {} already exists. Skipping..'.format(path))\n",
    "        return\n",
    "    # scraping the top repos in a dataframe\n",
    "    topic_repos_df = get_topic_repos(get_topic_page(topic_url))\n",
    "    # Creating the csv file of repos from dataframe and saving in the folder\n",
    "    topic_repos_df.to_csv(path, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3af117b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file top_repos/3d.csv already exists. Skipping..\n"
     ]
    }
   ],
   "source": [
    "scrape_topic('https://github.com/topics/3d', 'top_repos/3d.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdf2259",
   "metadata": {},
   "source": [
    "## Getting top repositories of all topics and saving them in CSV format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bd9bad",
   "metadata": {},
   "source": [
    "- We have the function to get the list of topics (a dataframe with topics information)\n",
    "- We have the function to create CSV file from scraped repos of each topic\n",
    "- Now putting them together in the following function, that saves the csv of all top repos of all topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4836372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics_repos():\n",
    "    print('Scraping topics..')\n",
    "    # Getting the dataframe containing info of topics\n",
    "    topics_df = scrape_topics()\n",
    "    print('Scraping top repositories of each topic and saving in CSV format\\n')\n",
    "    # Creating a folder to save CSV files of top repos\n",
    "    os.makedirs('Repos', exist_ok = True)\n",
    "    # Iterating through the topics dataframe to save top repos of each topic\n",
    "    for index, row in topics_df.iterrows():\n",
    "        print('Scraping top repositories for the topic \"{}\"'.format(row['title']))\n",
    "        scrape_topic(row['url'], 'Repos/{}.csv'.format(row['title']))\n",
    "    print('Process completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691fa67d",
   "metadata": {},
   "source": [
    "Now running the function to scrape top repos of all the topics on the first page of https://github.com/topics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97949230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping topics..\n",
      "Scraping top repositories of each topic and saving in CSV format\n",
      "\n",
      "Scraping top repositories for the topic \"3D\"\n",
      "The file Repos/3D.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"Ajax\"\n",
      "The file Repos/Ajax.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"Algorithm\"\n",
      "The file Repos/Algorithm.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"Amp\"\n",
      "The file Repos/Amp.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"Android\"\n",
      "The file Repos/Android.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"Angular\"\n",
      "The file Repos/Angular.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"Ansible\"\n",
      "The file Repos/Ansible.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"API\"\n",
      "The file Repos/API.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"Arduino\"\n",
      "The file Repos/Arduino.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"ASP.NET\"\n",
      "The file Repos/ASP.NET.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"Atom\"\n",
      "The file Repos/Atom.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"Awesome Lists\"\n",
      "The file Repos/Awesome Lists.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"Amazon Web Services\"\n",
      "The file Repos/Amazon Web Services.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"Azure\"\n",
      "The file Repos/Azure.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"Babel\"\n",
      "The file Repos/Babel.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"Bash\"\n",
      "The file Repos/Bash.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"Bitcoin\"\n",
      "The file Repos/Bitcoin.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"Bootstrap\"\n",
      "The file Repos/Bootstrap.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"Bot\"\n",
      "The file Repos/Bot.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"C\"\n",
      "The file Repos/C.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"Chrome\"\n",
      "The file Repos/Chrome.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"Chrome extension\"\n",
      "The file Repos/Chrome extension.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"Command line interface\"\n",
      "The file Repos/Command line interface.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"Clojure\"\n",
      "The file Repos/Clojure.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"Code quality\"\n",
      "The file Repos/Code quality.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"Code review\"\n",
      "The file Repos/Code review.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"Compiler\"\n",
      "The file Repos/Compiler.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"Continuous integration\"\n",
      "The file Repos/Continuous integration.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"COVID-19\"\n",
      "The file Repos/COVID-19.csv already exists. Skipping..\n",
      "Scraping top repositories for the topic \"C++\"\n",
      "The file Repos/C++.csv already exists. Skipping..\n",
      "Process completed\n"
     ]
    }
   ],
   "source": [
    "scrape_topics_repos()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13aa0c5",
   "metadata": {},
   "source": [
    "Checking on a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f34b147b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>repo name</th>\n",
       "      <th>repo url</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dotnet</td>\n",
       "      <td>AspNetCore.Docs</td>\n",
       "      <td>https://github.com/dotnet/AspNetCore.Docs</td>\n",
       "      <td>10800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aspnetboilerplate</td>\n",
       "      <td>aspnetboilerplate</td>\n",
       "      <td>https://github.com/aspnetboilerplate/aspnetboi...</td>\n",
       "      <td>10500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bitwarden</td>\n",
       "      <td>server</td>\n",
       "      <td>https://github.com/bitwarden/server</td>\n",
       "      <td>10200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abpframework</td>\n",
       "      <td>abp</td>\n",
       "      <td>https://github.com/abpframework/abp</td>\n",
       "      <td>8400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nopSolutions</td>\n",
       "      <td>nopCommerce</td>\n",
       "      <td>https://github.com/nopSolutions/nopCommerce</td>\n",
       "      <td>7400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ElectronNET</td>\n",
       "      <td>Electron.NET</td>\n",
       "      <td>https://github.com/ElectronNET/Electron.NET</td>\n",
       "      <td>6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RicoSuter</td>\n",
       "      <td>NSwag</td>\n",
       "      <td>https://github.com/RicoSuter/NSwag</td>\n",
       "      <td>5300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>thangchung</td>\n",
       "      <td>clean-code-dotnet</td>\n",
       "      <td>https://github.com/thangchung/clean-code-dotnet</td>\n",
       "      <td>5300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>smartstore</td>\n",
       "      <td>SmartStoreNET</td>\n",
       "      <td>https://github.com/smartstore/SmartStoreNET</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>JimBobSquarePants</td>\n",
       "      <td>ImageProcessor</td>\n",
       "      <td>https://github.com/JimBobSquarePants/ImageProc...</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dotnet</td>\n",
       "      <td>aspnet-api-versioning</td>\n",
       "      <td>https://github.com/dotnet/aspnet-api-versioning</td>\n",
       "      <td>2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>serenity-is</td>\n",
       "      <td>Serenity</td>\n",
       "      <td>https://github.com/serenity-is/Serenity</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>loic-sharma</td>\n",
       "      <td>BaGet</td>\n",
       "      <td>https://github.com/loic-sharma/BaGet</td>\n",
       "      <td>2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mjebrahimi</td>\n",
       "      <td>Awesome-Microservices-DotNet</td>\n",
       "      <td>https://github.com/mjebrahimi/Awesome-Microser...</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TrilonIO</td>\n",
       "      <td>aspnetcore-angular-universal</td>\n",
       "      <td>https://github.com/TrilonIO/aspnetcore-angular...</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TrilonIO</td>\n",
       "      <td>aspnetcore-Vue-starter</td>\n",
       "      <td>https://github.com/TrilonIO/aspnetcore-Vue-sta...</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MarimerLLC</td>\n",
       "      <td>csla</td>\n",
       "      <td>https://github.com/MarimerLLC/csla</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>riganti</td>\n",
       "      <td>dotvvm</td>\n",
       "      <td>https://github.com/riganti/dotvvm</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>antonioCoco</td>\n",
       "      <td>SharPyShell</td>\n",
       "      <td>https://github.com/antonioCoco/SharPyShell</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cornflourblue</td>\n",
       "      <td>aspnet-core-3-jwt-authentication-api</td>\n",
       "      <td>https://github.com/cornflourblue/aspnet-core-3...</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>json-api-dotnet</td>\n",
       "      <td>JsonApiDotNetCore</td>\n",
       "      <td>https://github.com/json-api-dotnet/JsonApiDotN...</td>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>chsakell</td>\n",
       "      <td>mvcarchitecture</td>\n",
       "      <td>https://github.com/chsakell/mvcarchitecture</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>brthor</td>\n",
       "      <td>Gofer.NET</td>\n",
       "      <td>https://github.com/brthor/Gofer.NET</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>YAFNET</td>\n",
       "      <td>YAFNET</td>\n",
       "      <td>https://github.com/YAFNET/YAFNET</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>IvanJosipovic</td>\n",
       "      <td>BlazorTable</td>\n",
       "      <td>https://github.com/IvanJosipovic/BlazorTable</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SapphireDb</td>\n",
       "      <td>SapphireDb</td>\n",
       "      <td>https://github.com/SapphireDb/SapphireDb</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Maarten88</td>\n",
       "      <td>rrod</td>\n",
       "      <td>https://github.com/Maarten88/rrod</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Taritsyn</td>\n",
       "      <td>WebMarkupMin</td>\n",
       "      <td>https://github.com/Taritsyn/WebMarkupMin</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>chsakell</td>\n",
       "      <td>aspnet-core-identity</td>\n",
       "      <td>https://github.com/chsakell/aspnet-core-identity</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>smartstore</td>\n",
       "      <td>Smartstore</td>\n",
       "      <td>https://github.com/smartstore/Smartstore</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             username                             repo name  \\\n",
       "0              dotnet                       AspNetCore.Docs   \n",
       "1   aspnetboilerplate                     aspnetboilerplate   \n",
       "2           bitwarden                                server   \n",
       "3        abpframework                                   abp   \n",
       "4        nopSolutions                           nopCommerce   \n",
       "5         ElectronNET                          Electron.NET   \n",
       "6           RicoSuter                                 NSwag   \n",
       "7          thangchung                     clean-code-dotnet   \n",
       "8          smartstore                         SmartStoreNET   \n",
       "9   JimBobSquarePants                        ImageProcessor   \n",
       "10             dotnet                 aspnet-api-versioning   \n",
       "11        serenity-is                              Serenity   \n",
       "12        loic-sharma                                 BaGet   \n",
       "13         mjebrahimi          Awesome-Microservices-DotNet   \n",
       "14           TrilonIO          aspnetcore-angular-universal   \n",
       "15           TrilonIO                aspnetcore-Vue-starter   \n",
       "16         MarimerLLC                                  csla   \n",
       "17            riganti                                dotvvm   \n",
       "18        antonioCoco                           SharPyShell   \n",
       "19      cornflourblue  aspnet-core-3-jwt-authentication-api   \n",
       "20    json-api-dotnet                     JsonApiDotNetCore   \n",
       "21           chsakell                       mvcarchitecture   \n",
       "22             brthor                             Gofer.NET   \n",
       "23             YAFNET                                YAFNET   \n",
       "24      IvanJosipovic                           BlazorTable   \n",
       "25         SapphireDb                            SapphireDb   \n",
       "26          Maarten88                                  rrod   \n",
       "27           Taritsyn                          WebMarkupMin   \n",
       "28           chsakell                  aspnet-core-identity   \n",
       "29         smartstore                            Smartstore   \n",
       "\n",
       "                                             repo url  stars  \n",
       "0           https://github.com/dotnet/AspNetCore.Docs  10800  \n",
       "1   https://github.com/aspnetboilerplate/aspnetboi...  10500  \n",
       "2                 https://github.com/bitwarden/server  10200  \n",
       "3                 https://github.com/abpframework/abp   8400  \n",
       "4         https://github.com/nopSolutions/nopCommerce   7400  \n",
       "5         https://github.com/ElectronNET/Electron.NET   6400  \n",
       "6                  https://github.com/RicoSuter/NSwag   5300  \n",
       "7     https://github.com/thangchung/clean-code-dotnet   5300  \n",
       "8         https://github.com/smartstore/SmartStoreNET   2500  \n",
       "9   https://github.com/JimBobSquarePants/ImageProc...   2500  \n",
       "10    https://github.com/dotnet/aspnet-api-versioning   2300  \n",
       "11            https://github.com/serenity-is/Serenity   2200  \n",
       "12               https://github.com/loic-sharma/BaGet   2100  \n",
       "13  https://github.com/mjebrahimi/Awesome-Microser...   1900  \n",
       "14  https://github.com/TrilonIO/aspnetcore-angular...   1500  \n",
       "15  https://github.com/TrilonIO/aspnetcore-Vue-sta...   1200  \n",
       "16                 https://github.com/MarimerLLC/csla   1000  \n",
       "17                  https://github.com/riganti/dotvvm    619  \n",
       "18         https://github.com/antonioCoco/SharPyShell    619  \n",
       "19  https://github.com/cornflourblue/aspnet-core-3...    616  \n",
       "20  https://github.com/json-api-dotnet/JsonApiDotN...    575  \n",
       "21        https://github.com/chsakell/mvcarchitecture    462  \n",
       "22                https://github.com/brthor/Gofer.NET    450  \n",
       "23                   https://github.com/YAFNET/YAFNET    434  \n",
       "24       https://github.com/IvanJosipovic/BlazorTable    412  \n",
       "25           https://github.com/SapphireDb/SapphireDb    385  \n",
       "26                  https://github.com/Maarten88/rrod    379  \n",
       "27           https://github.com/Taritsyn/WebMarkupMin    377  \n",
       "28   https://github.com/chsakell/aspnet-core-identity    374  \n",
       "29           https://github.com/smartstore/Smartstore    366  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read and display a CSV using Pandas\n",
    "\n",
    "pd.read_csv('Repos/ASP.NET.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44438ed4",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785be08a",
   "metadata": {},
   "source": [
    "1. First we scrape the list of topics from first page of https://github.com/topics in the form of Pandas dataframe\n",
    "- For that, we first download the page using requests and parse it using Beautiful Soup\n",
    "- Then we extract the following information of each topic- title, description and url\n",
    "- we extract each info separately by inspecting the web page in the browser\n",
    "- In this way, we get four functions, one for parsing the page and rest three for extracting information\n",
    "- Now, we put all functions together in a single function which gets the parsed page of topics and extract information of all topics on the first page and return a dataframe (first main function)\n",
    "2. Scraping top repositories of a topic and saving in CSV format\n",
    "- Before extracting top repositories of all topics, we first extract top repositories of first topic, '3d'\n",
    "- First we define a function to parse the page of repository page of the topic\n",
    "- Then we define a function which inspects the corresponding webpage and returns information of a single repo, which are username, repo name, repo url and stars. Alongside, we define a function that returns the stars in whole number.\n",
    "- Then we define the function which iterates through the index of all repositories, extracts required information of each repository by making use of above function, stores the lists of all categories of information in a dictionary and return a pandas dataframe created from that dictionary.\n",
    "- Now we define a function that takes the dataframe of top repos of each topic and saves its CSV file in a folder (second main function)\n",
    "3. Scraping top repos of all topics\n",
    "- Now we define a function that makes use of abpve two main function, first that returns the dataframe of all topics and second that saves CSV of top repos of each topic.\n",
    "- This function iterates through the dataframe of topics (from first main function), makes a folder to save all CSV files using os library and saves CSV file of top repos of each topic in that folder(from second main function)\n",
    "- Since 30 repos are there in first page of repos of all topics, total 30 repos are extracted for all 30 topics ( 30 topics are there on first page of topics) \n",
    "- Finally we can read and display the CSV files using Pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30855140",
   "metadata": {},
   "source": [
    "## Future Work\n",
    "\n",
    "- Extracting top repos not only from first page of topics, but from all pages of topics\n",
    "- Extracting repos not only from first page of repos, but from more pages, say top 100 repos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf0ec02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
